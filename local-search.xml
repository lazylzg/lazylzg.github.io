<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Markdown数学公式语法</title>
    <link href="/2020/04/06/2020-4-6-Markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/"/>
    <url>/2020/04/06/2020-4-6-Markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="行内与独行"><a href="#行内与独行" class="headerlink" title="行内与独行"></a>行内与独行</h1><ol><li> 行内公式：将公式插入到本行内，符号：<code>$公式内容$</code>，如：$xyz$</li><li> 独行公式：将公式插入到新的一行内，并且居中，符号：<code>$$公式内容$$</code>，如：$$xyz$$</li></ol><h1 id="上标、下标与组合"><a href="#上标、下标与组合" class="headerlink" title="上标、下标与组合"></a>上标、下标与组合</h1><ol><li> 上标符号，符号：<code>^</code>，如：$x^4$</li><li> 下标符号，符号：<code>_</code>，如：$x_1$</li><li> 组合符号，符号：<code>&#123;&#125;</code>，如：${16}<em>{8}O{2+}</em>{2}$</li></ol><h1 id="汉字、字体与格式"><a href="#汉字、字体与格式" class="headerlink" title="汉字、字体与格式"></a>汉字、字体与格式</h1><ol><li> 汉字形式，符号：<code>\mbox&#123;&#125;</code>，如：$V_{\mbox{初始}}$</li><li> 字体控制，符号：<code>\displaystyle</code>，如：$\displaystyle \frac{x+y}{y+z}$</li><li> 下划线符号，符号：<code>\underline</code>，如：$\underline{x+y}$</li><li> 标签，符号<code>\tag&#123;数字&#125;</code>，如：$\tag{11}$</li><li> 上大括号，符号：<code>\overbrace&#123;算式&#125;</code>，如：$\overbrace{a+b+c+d}^{2.0}$</li><li> 下大括号，符号：<code>\underbrace&#123;算式&#125;</code>，如：$a+\underbrace{b+c}_{1.0}+d$</li><li> 上位符号，符号：<code>\stacrel&#123;上位符号&#125;&#123;基位符号&#125;</code>，如：$\vec{x}\stackrel{\mathrm{def}}{=}{x_1,\dots,x_n}$</li></ol><h1 id="占位符"><a href="#占位符" class="headerlink" title="占位符"></a>占位符</h1><ol><li> 两个quad空格，符号：<code>\qquad</code>，如：$x \qquad y$</li><li> quad空格，符号：<code>\quad</code>，如：$x \quad y$</li><li> 大空格，符号<code>\</code>，如：$x \  y$</li><li> 中空格，符号<code>\:</code>，如：$x : y$</li><li> 小空格，符号<code>\,</code>，如：$x , y$</li><li> 没有空格，符号``，如：$xy$</li><li> 紧贴，符号<code>\!</code>，如：$x ! y$</li></ol><h1 id="定界符与组合"><a href="#定界符与组合" class="headerlink" title="定界符与组合"></a>定界符与组合</h1><ol><li> 括号，符号：<code>（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)</code>，如：$（）\big(\big) \Big(\Big) \bigg(\bigg) \Bigg(\Bigg)$</li><li> 中括号，符号：<code>[]</code>，如：$[x+y]$</li><li> 大括号，符号：<code>\&#123; \&#125;</code>，如：${x+y}$</li><li> 自适应括号，符号：<code>\left \right</code>，如：$\left(x\right)$，$\left(x{yz}\right)$</li><li> 组合公式，符号：<code>&#123;上位公式 \choose 下位公式&#125;</code>，如：${n+1 \choose k}={n \choose k}+{n \choose k-1}$</li><li> 组合公式，符号：<code>&#123;上位公式 \atop 下位公式&#125;</code>，如：$\sum_{k_0,k_1,\ldots&gt;0 \atop k_0+k_1+\cdots=n}A_{k_0}A_{k_1}\cdots$</li></ol><h1 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h1><ol><li> 加法运算，符号：<code>+</code>，如：$x+y=z$</li><li> 减法运算，符号：<code>-</code>，如：$x-y=z$</li><li> 加减运算，符号：<code>\pm</code>，如：$x \pm y=z$</li><li> 减甲运算，符号：<code>\mp</code>，如：$x \mp y=z$</li><li> 乘法运算，符号：<code>\times</code>，如：$x \times y=z$</li><li> 点乘运算，符号：<code>\cdot</code>，如：$x \cdot y=z$</li><li> 星乘运算，符号：<code>\ast</code>，如：$x \ast y=z$</li><li> 除法运算，符号：<code>\div</code>，如：$x \div y=z$</li><li> 斜法运算，符号：<code>/</code>，如：$x/y=z$</li><li> 分式表示，符号：<code>\frac&#123;分子&#125;&#123;分母&#125;</code>，如：$\frac{x+y}{y+z}$</li><li> 分式表示，符号：<code>&#123;分子&#125; \voer &#123;分母&#125;</code>，如：${x+y} \over {y+z}$</li><li> 绝对值表示，符号：<code>||</code>，如：$|x+y|$</li></ol><h1 id="高级运算"><a href="#高级运算" class="headerlink" title="高级运算"></a>高级运算</h1><ol><li> 平均数运算，符号：<code>\overline&#123;算式&#125;</code>，如：$\overline{xyz}$</li><li> 开二次方运算，符号：<code>\sqrt</code>，如：$\sqrt x$</li><li> 开方运算，符号：<code>\sqrt[开方数]&#123;被开方数&#125;</code>，如：$\sqrt[3]{x+y}$</li><li> 对数运算，符号：<code>\log</code>，如：$\log(x)$</li><li> 极限运算，符号：<code>\lim</code>，如：$\lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li> 极限运算，符号：<code>\displaystyle \lim</code>，如：$\displaystyle \lim^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li> 求和运算，符号：<code>\sum</code>，如：$\sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li> 求和运算，符号：<code>\displaystyle \sum</code>，如：$\displaystyle \sum^{x \to \infty}_{y \to 0}{\frac{x}{y}}$</li><li> 积分运算，符号：<code>\int</code>，如：$\int^{\infty}_{0}{xdx}$</li><li> 积分运算，符号：<code>\displaystyle \int</code>，如：$\displaystyle \int^{\infty}_{0}{xdx}$</li><li> 微分运算，符号：<code>\partial</code>，如：$\frac{\partial x}{\partial y}$</li><li> 矩阵表示，符号：<code>\begin&#123;matrix&#125; \end&#123;matrix&#125;</code>，如：$\left[ \begin{matrix} 1 &amp;2 &amp;\cdots &amp;4\5 &amp;6 &amp;\cdots &amp;8\vdots &amp;\vdots &amp;\ddots &amp;\vdots\13 &amp;14 &amp;\cdots &amp;16\end{matrix} \right]$</li></ol><h1 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h1><ol><li> 等于运算，符号：<code>=</code>，如：$x+y=z$</li><li> 大于运算，符号：<code>&gt;</code>，如：$x+y&gt;z$</li><li> 小于运算，符号：<code>&lt;</code>，如：$x+y&lt;z$</li><li> 大于等于运算，符号：<code>\geq</code>，如：$x+y \geq z$</li><li> 小于等于运算，符号：<code>\leq</code>，如：$x+y \leq z$</li><li> 不等于运算，符号：<code>\neq</code>，如：$x+y \neq z$</li><li> 不大于等于运算，符号：<code>\ngeq</code>，如：$x+y \ngeq z$</li><li> 不大于等于运算，符号：<code>\not\geq</code>，如：$x+y \not\geq z$</li><li> 不小于等于运算，符号：<code>\nleq</code>，如：$x+y \nleq z$</li><li> 不小于等于运算，符号：<code>\not\leq</code>，如：$x+y \not\leq z$</li><li> 约等于运算，符号：<code>\approx</code>，如：$x+y \approx z$</li><li> 恒定等于运算，符号：<code>\equiv</code>，如：$x+y \equiv z$</li></ol><h1 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a>集合运算</h1><ol><li> 属于运算，符号：<code>\in</code>，如：$x \in y$</li><li> 不属于运算，符号：<code>\notin</code>，如：$x \notin y$</li><li> 不属于运算，符号：<code>\not\in</code>，如：$x \not\in y$</li><li> 子集运算，符号：<code>\subset</code>，如：$x \subset y$</li><li> 子集运算，符号：<code>\supset</code>，如：$x \supset y$</li><li> 真子集运算，符号：<code>\subseteq</code>，如：$x \subseteq y$</li><li> 非真子集运算，符号：<code>\subsetneq</code>，如：$x \subsetneq y$</li><li> 真子集运算，符号：<code>\supseteq</code>，如：$x \supseteq y$</li><li> 非真子集运算，符号：<code>\supsetneq</code>，如：$x \supsetneq y$</li><li> 非子集运算，符号：<code>\not\subset</code>，如：$x \not\subset y$</li><li> 非子集运算，符号：<code>\not\supset</code>，如：$x \not\supset y$</li><li> 并集运算，符号：<code>\cup</code>，如：$x \cup y$</li><li> 交集运算，符号：<code>\cap</code>，如：$x \cap y$</li><li> 差集运算，符号：<code>\setminus</code>，如：$x \setminus y$</li><li> 同或运算，符号：<code>\bigodot</code>，如：$x \bigodot y$</li><li> 同与运算，符号：<code>\bigotimes</code>，如：$x \bigotimes y$</li><li> 实数集合，符号：<code>\mathbb&#123;R&#125;</code>，如：<code>\mathbb&#123;R&#125;</code> </li><li> 自然数集合，符号：<code>\mathbb&#123;Z&#125;</code>，如：<code>\mathbb&#123;Z&#125;</code> </li><li> 空集，符号：<code>\emptyset</code>，如：$\emptyset$</li></ol><h1 id="数学符号"><a href="#数学符号" class="headerlink" title="数学符号"></a>数学符号</h1><ol><li> 无穷，符号：<code>\infty</code>，如：$\infty$</li><li> 虚数，符号：<code>\imath</code>，如：$\imath$</li><li> 虚数，符号：<code>\jmath</code>，如：$\jmath$</li><li> 数学符号，符号<code>\hat&#123;a&#125;</code>，如：$\hat{a}$</li><li> 数学符号，符号<code>\check&#123;a&#125;</code>，如：$\check{a}$</li><li> 数学符号，符号<code>\breve&#123;a&#125;</code>，如：$\breve{a}$</li><li> 数学符号，符号<code>\tilde&#123;a&#125;</code>，如：$\tilde{a}$</li><li> 数学符号，符号<code>\bar&#123;a&#125;</code>，如：$\bar{a}$</li><li> 矢量符号，符号<code>\vec&#123;a&#125;</code>，如：$\vec{a}$</li><li> 数学符号，符号<code>\acute&#123;a&#125;</code>，如：$\acute{a}$</li><li> 数学符号，符号<code>\grave&#123;a&#125;</code>，如：$\grave{a}$</li><li> 数学符号，符号<code>\mathring&#123;a&#125;</code>，如：$\mathring{a}$</li><li> 一阶导数符号，符号<code>\dot&#123;a&#125;</code>，如：$\dot{a}$</li><li> 二阶导数符号，符号<code>\ddot&#123;a&#125;</code>，如：$\ddot{a}$</li><li> 上箭头，符号：<code>\uparrow</code>，如：$\uparrow$</li><li> 上箭头，符号：<code>\Uparrow</code>，如：$\Uparrow$</li><li> 下箭头，符号：<code>\downarrow</code>，如：$\downarrow$</li><li> 下箭头，符号：<code>\Downarrow</code>，如：$\Downarrow$</li><li> 左箭头，符号：<code>\leftarrow</code>，如：$\leftarrow$</li><li> 左箭头，符号：<code>\Leftarrow</code>，如：$\Leftarrow$</li><li> 右箭头，符号：<code>\rightarrow</code>，如：$\rightarrow$</li><li> 右箭头，符号：<code>\Rightarrow</code>，如：$\Rightarrow$</li><li> 底端对齐的省略号，符号：<code>\ldots</code>，如：$1,2,\ldots,n$</li><li> 中线对齐的省略号，符号：<code>\cdots</code>，如：$x_1^2 + x_2^2 + \cdots + x_n^2$</li><li> 竖直对齐的省略号，符号：<code>\vdots</code>，如：$\vdots$</li><li> 斜对齐的省略号，符号：<code>\ddots</code>，如：$\ddots$</li></ol><h1 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h1><table><thead><tr><th>字母</th><th>实现</th><th>字母</th><th>实现</th></tr></thead><tbody><tr><td>A</td><td><code>A</code></td><td>α</td><td><code>\alhpa</code></td></tr><tr><td>B</td><td><code>B</code></td><td>β</td><td><code>\beta</code></td></tr><tr><td>Γ</td><td><code>\Gamma</code></td><td>γ</td><td><code>\gamma</code></td></tr><tr><td>Δ</td><td><code>\Delta</code></td><td>δ</td><td><code>\delta</code></td></tr><tr><td>E</td><td><code>E</code></td><td>ϵ</td><td><code>\epsilon</code></td></tr><tr><td>Z</td><td><code>Z</code></td><td>ζ</td><td><code>\zeta</code></td></tr><tr><td>H</td><td><code>H</code></td><td>η</td><td><code>\eta</code></td></tr><tr><td>Θ</td><td><code>\Theta</code></td><td>θ</td><td><code>\theta</code></td></tr><tr><td>I</td><td><code>I</code></td><td>ι</td><td><code>\iota</code></td></tr><tr><td>K</td><td><code>K</code></td><td>κ</td><td><code>\kappa</code></td></tr><tr><td>Λ</td><td><code>\Lambda</code></td><td>λ</td><td><code>\lambda</code></td></tr><tr><td>M</td><td><code>M</code></td><td>μ</td><td><code>\mu</code></td></tr><tr><td>N</td><td><code>N</code></td><td>ν</td><td><code>\nu</code></td></tr><tr><td>Ξ</td><td><code>\Xi</code></td><td>ξ</td><td><code>\xi</code></td></tr><tr><td>O</td><td><code>O</code></td><td>ο</td><td><code>\omicron</code></td></tr><tr><td>Π</td><td><code>\Pi</code></td><td>π</td><td><code>\pi</code></td></tr><tr><td>P</td><td><code>P</code></td><td>ρ</td><td><code>\rho</code></td></tr><tr><td>Σ</td><td><code>\Sigma</code></td><td>σ</td><td><code>\sigma</code></td></tr><tr><td>T</td><td><code>T</code></td><td>τ</td><td><code>\tau</code></td></tr><tr><td>Υ</td><td><code>\Upsilon</code></td><td>υ</td><td><code>\upsilon</code></td></tr><tr><td>Φ</td><td><code>\Phi</code></td><td>ϕ</td><td><code>\phi</code></td></tr><tr><td>X</td><td><code>X</code></td><td>χ</td><td><code>\chi</code></td></tr><tr><td>Ψ</td><td><code>\Psi</code></td><td>ψ</td><td><code>\psi</code></td></tr><tr><td>Ω</td><td><code>\v</code></td><td>ω</td><td><code>\omega</code></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Markdown</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TensorFlow基础</title>
    <link href="/2020/03/29/2020-3-29-TensorFlow%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/03/29/2020-3-29-TensorFlow%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><h2 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h2><ul><li>  标量（Scalar），单个实数，如1.2,3,4等，维度（Dimension）数为0，shape为[]。</li></ul><pre><code class="hljs python"><span class="hljs-comment"># python 语言创建标量</span>a = <span class="hljs-number">1.2</span><span class="hljs-comment"># TensorFlow 创建标量</span>aa = tf.constant(<span class="hljs-number">1.2</span>)print(<span class="hljs-built_in">type</span>(a), <span class="hljs-built_in">type</span>(aa), tf.is_tensor(a))<span class="hljs-comment">#&lt;class &#x27;float&#x27;&gt; &lt;class &#x27;tensorflow.python.framework.ops.EagerTensor&#x27;&gt; False</span></code></pre><ul><li>  向量（Vector），n个实数的有序集合，如[1.2]，[1, 2, 3, 4]等，维度为1，长度不定。</li></ul><pre><code class="hljs python"><span class="hljs-comment"># 创建1个元素的向量</span>a = tf.constant([<span class="hljs-number">1.1</span>])print(a, a.shape)<span class="hljs-comment"># 创建3个元素的向量</span>b = tf.constant([<span class="hljs-number">1.</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3.3</span>])print(b, b.shape)<span class="hljs-comment">#tf.Tensor([1.1], shape=(1,), dtype=float32) (1,)</span><span class="hljs-comment">#tf.Tensor([1.  2.  3.3], shape=(3,), dtype=float32) (3,)</span></code></pre><ul><li>  矩阵（Matrix），n行m列实数集合，如[[1, 2], [3, 4]]</li></ul><pre><code class="hljs python"><span class="hljs-comment"># 创建2行2列的矩阵</span>c = tf.constant([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])print(c, c.shape)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[1 2]</span><span class="hljs-comment"># [3 4]], shape=(2, 2), dtype=int32) (2, 2)</span></code></pre><ul><li>  张量（Tensor），所有维度数大于2的数组统称张量。</li></ul><pre><code class="hljs python">x = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3.0</span>])print(x)<span class="hljs-comment"># 将 tf 张量的数据导出为 numpy 数组格式</span>print(x.numpy())<span class="hljs-comment">#tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)</span><span class="hljs-comment">#[1. 2. 3.]</span></code></pre><h2 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h2><pre><code class="hljs python"><span class="hljs-comment"># 创建字符串</span>s = tf.constant(<span class="hljs-string">&#x27;Hello World!&#x27;</span>)print(s)<span class="hljs-comment"># 小写化字符串</span>s = tf.strings.lower(s)print(s)<span class="hljs-comment">#tf.Tensor(b&#x27;Hello World!&#x27;, shape=(), dtype=string)</span><span class="hljs-comment">#tf.Tensor(b&#x27;hello world!&#x27;, shape=(), dtype=string)</span></code></pre><h2 id="布尔类型"><a href="#布尔类型" class="headerlink" title="布尔类型"></a>布尔类型</h2><pre><code class="hljs python"><span class="hljs-comment"># 创建布尔型标量</span>a = tf.constant(<span class="hljs-literal">True</span>)print(a)<span class="hljs-comment"># 创建布尔型向量</span>b = tf.constant([<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>])print(b)<span class="hljs-comment">#tf.Tensor(True, shape=(), dtype=bool)</span><span class="hljs-comment">#tf.Tensor([ True False], shape=(2,), dtype=bool)</span></code></pre><h1 id="数值精度"><a href="#数值精度" class="headerlink" title="数值精度"></a>数值精度</h1><pre><code class="hljs python"><span class="hljs-comment"># 创建指定的张量</span>a = tf.constant(<span class="hljs-number">123456789</span>, dtype=tf.int16)print(a)b = tf.constant(<span class="hljs-number">123456789</span>, dtype=tf.int32)print(b)<span class="hljs-comment">#tf.Tensor(-13035, shape=(), dtype=int16)</span><span class="hljs-comment">#tf.Tensor(123456789, shape=(), dtype=int32)</span></code></pre><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-comment"># np.pi 从 numpy 中导入 pi 常量</span><span class="hljs-comment"># 32位</span>a = tf.constant(np.pi, dtype=tf.float32)print(a)<span class="hljs-comment"># 64位</span>b = tf.constant(np.pi, dtype=tf.float64)print(b)<span class="hljs-comment">#tf.Tensor(3.1415927, shape=(), dtype=float32)</span><span class="hljs-comment">#tf.Tensor(3.141592653589793, shape=(), dtype=float64)</span></code></pre><h2 id="读取精度"><a href="#读取精度" class="headerlink" title="读取精度"></a>读取精度</h2><p>通过访问张量的 dtype 成员属性可以判断张量的保存精度</p><pre><code class="hljs python">a = tf.constant(np.pi, dtype=tf.float16)<span class="hljs-comment"># 读取原有张量的数值精度</span>print(<span class="hljs-string">&#x27;before:&#x27;</span>, a.dtype)<span class="hljs-comment"># 如果精度不符合要求，则进行转换</span><span class="hljs-keyword">if</span> a.dtype != tf.float32:    <span class="hljs-comment"># tf.cast 函数可以完成精度转换</span>    a = tf.cast(a, tf.float32)<span class="hljs-comment"># 打印转换后的精度</span>print(<span class="hljs-string">&#x27;after :&#x27;</span>, a.dtype)<span class="hljs-comment">#before: &lt;dtype: &#x27;float16&#x27;&gt;</span><span class="hljs-comment">#after : &lt;dtype: &#x27;float32&#x27;&gt;</span></code></pre><h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><p>通过 tf.cast 函数进行转换</p><pre><code class="hljs python"><span class="hljs-comment"># 创建tf.float16 低精度张量</span>a = tf.constant(np.pi, dtype=tf.float16)<span class="hljs-comment"># 转换为高精度张量</span>tf.cast(a, tf.double)<span class="hljs-comment">#Out[32]: &lt;tf.Tensor: shape=(), dtype=float64, numpy=3.140625&gt;</span></code></pre><p>进行类型转换时，需要保证转换操作的合法性，例如将高精度的张量转换为低精度的张量<br>时，可能发生数据溢出隐患：</p><pre><code class="hljs python">a = tf.constant(<span class="hljs-number">123456789</span>, dtype=tf.int32)<span class="hljs-comment"># 转换为低精度整型</span>tf.cast(a, tf.int16)<span class="hljs-comment">#Out[33]: &lt;tf.Tensor: shape=(), dtype=int16, numpy=-13035&gt;</span></code></pre><h1 id="待优化张量"><a href="#待优化张量" class="headerlink" title="待优化张量"></a>待优化张量</h1><p>为了区分需要计算梯度信息的张量与不需要计算梯度信息的张量，TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录：tf.Variable。tf.Variable 类型在普通的张量类型基础上添加了name，trainable 等属性来支持计算图的构建。由于梯度运算会消耗大量的计算资源，而且会自动更新相关参数，对于不需要的优化的张量，如神经网络的输入𝑿，不需要通过tf.Variable 封装；相反，对于需要计算梯度并优化的张量，如神经网络层的𝑾和𝒃，需要通过tf.Variable 包裹以便TensorFlow 跟踪相关梯度信息。</p><pre><code class="hljs python"><span class="hljs-comment"># 创建TF 张量</span>a = tf.constant([-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<span class="hljs-comment"># 转换为Variable 类型</span>aa = tf.Variable(a)<span class="hljs-comment"># Variable 类型张量的属性</span>aa.name, aa.trainable<span class="hljs-comment">#Out[35]: (&#x27;Variable:0&#x27;, True)</span></code></pre><p>其中张量的name 和trainable 属性是Variable 特有的属性，name 属性用于命名计算图中的变量，这套命名体系是 TensorFlow 内部维护的，一般不需要用户关注name 属性；trainable 属性表征当前张量是否需要被优化，创建 Variable 对象时是默认启用优化标志，可以设置 trainable=False 来设置张量不需要优化。</p><p>除了通过普通张量方式创建Variable，也可以直接创建，例如：</p><pre><code class="hljs python"><span class="hljs-comment"># 直接创建Variable 张量</span>tf.Variable([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])<span class="hljs-comment">#&lt;tf.Variable &#x27;Variable:0&#x27; shape=(2, 2) dtype=int32, numpy=</span><span class="hljs-comment">#array([[1, 2],</span><span class="hljs-comment">#       [3, 4]])&gt;</span></code></pre><h1 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h1><h2 id="从数组、列表对象创建"><a href="#从数组、列表对象创建" class="headerlink" title="从数组、列表对象创建"></a>从数组、列表对象创建</h2><p>通过 tf.convert_to_tensor 函数可以创建新Tensor，并将保存在Python List 对象或者 Numpy Array 对象中的数据导入到新Tensor 中，例如：</p><pre><code class="hljs python"><span class="hljs-comment"># 从列表创建张量</span>tf.convert_to_tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2.</span>])<span class="hljs-comment"># 从数组中创建张量</span>tf.convert_to_tensor(np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">2.</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]]))<span class="hljs-comment">#Out[39]: &lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</span><span class="hljs-comment">#Out[40]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=float64, numpy=</span><span class="hljs-comment">#array([[1., 2.],</span><span class="hljs-comment">#       [3., 4.]])&gt;</span></code></pre><h2 id="创建全0-或全1-张量"><a href="#创建全0-或全1-张量" class="headerlink" title="创建全0 或全1 张量"></a>创建全0 或全1 张量</h2><p>通过 tf.zeros() 和 tf.ones() 即可创建任意形状，且内容全0 或全1 的张量。</p><p>创建为0 和为1 的标量：</p><pre><code class="hljs python"><span class="hljs-comment"># 创建全0，全1 的标量</span>tf.zeros([]), tf.ones([])<span class="hljs-comment">#Out[43]: </span><span class="hljs-comment">#(&lt;tf.Tensor: shape=(), dtype=float32, numpy=0.0&gt;,</span><span class="hljs-comment"># &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.0&gt;)</span></code></pre><p>创建全 0 和全1 的向量：</p><pre><code class="hljs python"><span class="hljs-comment"># 创建全0，全1 的向量</span>tf.zeros([<span class="hljs-number">1</span>]), tf.ones([<span class="hljs-number">1</span>])<span class="hljs-comment">#Out[44]: </span><span class="hljs-comment">#(&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)&gt;,</span><span class="hljs-comment"># &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)&gt;)</span></code></pre><p>创建全 0 和全1 的矩阵：</p><pre><code class="hljs python"><span class="hljs-comment"># 创建全 0 和全1 的矩阵</span>tf.zeros([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]), tf.ones([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>])<span class="hljs-comment">#Out[45]: </span><span class="hljs-comment">#(&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=</span><span class="hljs-comment"># array([[0., 0.],</span><span class="hljs-comment">#        [0., 0.]], dtype=float32)&gt;,</span><span class="hljs-comment"># &lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=</span><span class="hljs-comment"># array([[1., 1.],</span><span class="hljs-comment">#        [1., 1.],</span><span class="hljs-comment">#        [1., 1.]], dtype=float32)&gt;)</span></code></pre><p>通过 tf.zeros_like，tf.ones_like 可以方便地<strong>新建</strong>与某个张量shape 一致，且内容为全0 或全1 的张量。</p><pre><code class="hljs python"><span class="hljs-comment"># 创建一个矩阵</span>a = tf.ones([<span class="hljs-number">2</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 创建一个矩阵</span>b = tf.zeros([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>])<span class="hljs-comment"># 创建一个与a 形状相同，但是全0 的新矩阵</span>tf.zeros_like(a), tf.ones_like(a)<span class="hljs-comment">#Out[47]: </span><span class="hljs-comment">#(&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=</span><span class="hljs-comment"># array([[0., 0., 0.],</span><span class="hljs-comment">#        [0., 0., 0.]], dtype=float32)&gt;,</span><span class="hljs-comment"># &lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=</span><span class="hljs-comment"># array([[1., 1., 1.],</span><span class="hljs-comment">#        [1., 1., 1.]], dtype=float32)&gt;)</span></code></pre><h2 id="创建自定义数值张量"><a href="#创建自定义数值张量" class="headerlink" title="创建自定义数值张量"></a>创建自定义数值张量</h2><pre><code class="hljs python"><span class="hljs-comment"># 创建-1 的标量</span>tf.fill([], -<span class="hljs-number">1</span>)<span class="hljs-comment">#Out[48]: &lt;tf.Tensor: shape=(), dtype=int32, numpy=-1&gt;</span><span class="hljs-comment"># 创建-1 的向量</span>tf.fill([<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)<span class="hljs-comment">#Out[49]: &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([-1])&gt;</span><span class="hljs-comment"># 创建2 行2 列，元素全为99 的矩阵</span>tf.fill([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], <span class="hljs-number">99</span>)<span class="hljs-comment">#Out[50]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=</span><span class="hljs-comment">#array([[99, 99],</span><span class="hljs-comment">#       [99, 99]])&gt;</span></code></pre><h2 id="创建已知分布的张量"><a href="#创建已知分布的张量" class="headerlink" title="创建已知分布的张量"></a>创建已知分布的张量</h2><p>通过 tf.random.normal(shape, mean=0.0, stddev = 1.0)可以创建形状为shape，均值为 mean，标准差为stddev 的正态分布𝒩(mean, stddev2)。</p><pre><code class="hljs python"><span class="hljs-comment"># 创建标准正态分布的张量</span>tf.random.normal([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<span class="hljs-comment">#Out[51]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=</span><span class="hljs-comment">#array([[ 0.5267555 ,  1.0245267 ],</span><span class="hljs-comment">#       [-0.38253555, -1.3879421 ]], dtype=float32)&gt;</span><span class="hljs-comment"># 创建均值为1，标准差为2 的正态分布</span>tf.random.normal([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], mean=<span class="hljs-number">1</span>, stddev=<span class="hljs-number">2</span>)<span class="hljs-comment">#Out[52]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=</span><span class="hljs-comment">#array([[-1.3101618,  2.3768656],</span><span class="hljs-comment">#       [ 3.5436885,  1.8762882]], dtype=float32)&gt;</span></code></pre><p>通过 tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)可以创建采样自[minval, maxval)区间的均匀分布的张量。</p><pre><code class="hljs python"><span class="hljs-comment"># 创建采样自[0,1)均匀分布的矩阵</span>tf.random.uniform([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<span class="hljs-comment">#Out[53]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=</span><span class="hljs-comment">#array([[0.54303396, 0.8830224 ],</span><span class="hljs-comment">#       [0.29734194, 0.94715846]], dtype=float32)&gt;</span><span class="hljs-comment"># 创建采样自区间[0,10)，shape 为[2,2]的矩阵</span>tf.random.uniform([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], maxval=<span class="hljs-number">10</span>)<span class="hljs-comment">#Out[58]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=</span><span class="hljs-comment">#array([[5.781268 , 8.726329 ],</span><span class="hljs-comment">#       [1.5149117, 8.840149 ]], dtype=float32)&gt;</span></code></pre><p>如果需要均匀采样整形类型的数据，必须指定采样区间的最大值 maxval 参数，同时指定数据类型为 tf.int* 型：</p><pre><code class="hljs python"><span class="hljs-comment"># 创建采样自[0,100)均匀分布的整型矩阵</span>tf.random.uniform([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>], maxval=<span class="hljs-number">100</span>, dtype=tf.int32)<span class="hljs-comment">#Out[59]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 2), dtype=int32, numpy=</span><span class="hljs-comment">#array([[76, 86],</span><span class="hljs-comment">#       [53, 28]])&gt;</span></code></pre><h2 id="创建序列"><a href="#创建序列" class="headerlink" title="创建序列"></a>创建序列</h2><pre><code class="hljs python"><span class="hljs-comment"># 0~10，不包含10</span>tf.<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)<span class="hljs-comment">#Out[60]: &lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])&gt;</span><span class="hljs-comment"># 0~10，步长为2</span>tf.<span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>, delta=<span class="hljs-number">2</span>)<span class="hljs-comment">#Out[61]: &lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8])&gt;</span><span class="hljs-comment"># 2~10</span>tf.<span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, <span class="hljs-number">10</span>, delta=<span class="hljs-number">2</span>)<span class="hljs-comment">#Out[62]: &lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([2, 4, 6, 8])&gt;</span></code></pre><h1 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h1><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><pre><code class="hljs python"><span class="hljs-comment"># 创建4D张量</span>x = tf.random.normal([<span class="hljs-number">4</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 取第1张图片的数据</span>x[<span class="hljs-number">0</span>]<span class="hljs-comment">#Out[3]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[-4.22283739e-01,  1.12282026e+00,  5.82848310e-01],</span><span class="hljs-comment">#        [-1.11039448e+00,  8.52484107e-01, -7.36349642e-01],</span><span class="hljs-comment">#        [-4.43234473e-01, -7.96303034e-01, -1.39369264e-01],</span><span class="hljs-comment">#        ...,</span><span class="hljs-comment">#        [ 3.56604964e-01,  1.80101013e+00,  1.25016725e+00],</span><span class="hljs-comment">#        [ 1.87405634e+00, -4.38889146e-01, -1.64619851e+00],</span><span class="hljs-comment">#        [ 1.48716550e-02,  9.12306726e-01, -1.21598518e+00]]],</span><span class="hljs-comment">#      dtype=float32)&gt;</span><span class="hljs-comment"># 取第1张图片的第2行</span>x[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<span class="hljs-comment">#Out[4]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(32, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[ 1.5910356e+00, -8.5894281e-01,  4.5708373e-01],</span><span class="hljs-comment">#       [ 7.9057968e-01, -1.3268896e+00,  1.1165951e+00],</span><span class="hljs-comment">#       [ 9.6109343e-01,  2.2252908e-01, -7.0836329e-01],...,</span><span class="hljs-comment">#       [-5.8272004e-01,  7.4958265e-01, -3.2686439e-01]], dtype=float32)&gt;</span><span class="hljs-comment"># 取第1张图片的第2行的第3列</span>x[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>][<span class="hljs-number">3</span>]<span class="hljs-comment">#Out[5]: &lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([-3.439938 ,  0.7158939, -0.2061273], dtype=float32)&gt;</span><span class="hljs-comment"># 取第3张图片，第2行，第1列的像素，B 通道(第2 个通道)颜色强度值</span>x[<span class="hljs-number">2</span>][<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<span class="hljs-comment">#Out[7]: &lt;tf.Tensor: shape=(), dtype=float32, numpy=1.1827037&gt;</span></code></pre><p>当张量的维度数较高时，使用[𝑖][𝑗]. . . [𝑘]的方式书写不方便，可以采用[𝑖, 𝑗, … , 𝑘]的方索引，它们是等价的。</p><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><p>通过start: end: step切片方式可以方便地提取一段数据，其中start 为开始读取位置的索引，end 为结束读取位置的索引(不包含end 位)，step 为采样步长。</p><pre><code class="hljs python"><span class="hljs-comment"># 创建4D张量</span>x = tf.random.normal([<span class="hljs-number">4</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 读取第2,3 张图片</span>x[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]<span class="hljs-comment">#Out[8]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 32, 32, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[[-0.5387477 , -0.98211324,  0.3736743 ],</span><span class="hljs-comment">#         [-1.5512782 , -1.2625393 ,  0.12689345],</span><span class="hljs-comment">#         [ 0.933382  ,  0.23778425, -1.4852659 ],</span><span class="hljs-comment">#         ...,</span></code></pre><p>start: end: step切片方式有很多简写方式，其中start、end、step 3 个参数可以根据需要选择性地省略，全部省略时即为::，表示从最开始读取到最末尾，步长为1，即不跳过任何元素。如x[0,::]表示读取第1 张图片的所有行，其中::表示在行维度上读取所有行，它等价于x[0]的写法：</p><pre><code class="hljs python"><span class="hljs-comment"># 取第1张图片</span>x[<span class="hljs-number">0</span>, ::]<span class="hljs-comment">#Out[9]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(32, 32, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[ 0.25870258,  0.20981076,  0.31078792],</span><span class="hljs-comment">#        [-0.17310825, -0.2321168 ,  1.4408395 ],</span><span class="hljs-comment">#        [ 0.47256398,  1.8767792 , -0.41517937],</span><span class="hljs-comment">#        ...,</span>x[:,<span class="hljs-number">0</span>:<span class="hljs-number">28</span>:<span class="hljs-number">2</span>, <span class="hljs-number">0</span>:<span class="hljs-number">28</span>:<span class="hljs-number">2</span>, :]<span class="hljs-comment">#Out[10]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(4, 14, 14, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[[ 0.25870258,  0.20981076,  0.31078792],</span><span class="hljs-comment">#         [ 0.47256398,  1.8767792 , -0.41517937],</span><span class="hljs-comment">#         [-1.4870992 ,  0.77554166,  0.74479437],</span><span class="hljs-comment">#         ...,</span></code></pre><pre><code class="hljs python"><span class="hljs-comment"># 创建0~9 向量</span>x = tf.<span class="hljs-built_in">range</span>(<span class="hljs-number">9</span>)<span class="hljs-comment"># 从8 取到0，逆序，不包含0</span>x[<span class="hljs-number">8</span>:<span class="hljs-number">0</span>:-<span class="hljs-number">1</span>] <span class="hljs-comment">#Out[11]: &lt;tf.Tensor: shape=(8,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1])&gt;</span><span class="hljs-comment"># 逆序全部元素</span>x[::-<span class="hljs-number">1</span>]<span class="hljs-comment">#Out[12]: &lt;tf.Tensor: shape=(9,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1, 0])&gt;</span><span class="hljs-comment"># 逆序间隔采样</span>x[::-<span class="hljs-number">2</span>]<span class="hljs-comment">#Out[13]: &lt;tf.Tensor: shape=(5,), dtype=int32, numpy=array([8, 6, 4, 2, 0])&gt;</span></code></pre><p>读取每张图片的所有通道，其中行按着逆序隔行采样，列按着逆序隔行采样，实现如下：</p><pre><code class="hljs python"><span class="hljs-comment"># 创建4D张量</span>x = tf.random.normal([<span class="hljs-number">4</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 行、列逆序间隔采样</span>x[<span class="hljs-number">0</span>, ::-<span class="hljs-number">2</span>, ::-<span class="hljs-number">2</span>]<span class="hljs-comment">#Out[14]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(16, 16, 3), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[-6.40726149e-01, -1.64043710e-01, -4.14758682e-01],</span><span class="hljs-comment">#        [ 8.83031189e-01, -2.15735650e+00,  7.45904207e-01],...,</span><span class="hljs-comment">#        [ 1.77812195e+00, -4.44908082e-01,  1.71278393e+00],</span><span class="hljs-comment">#        [-9.77649391e-02, -2.56478786e-02,  1.69697809e+00]],...,</span><span class="hljs-comment">#       [[-1.24988317e+00, -4.40455347e-01, -9.40938056e-01],</span><span class="hljs-comment">#        [-3.51193339e-01, -1.69094354e-01, -1.55378059e-01],...,</span><span class="hljs-comment">#        [ 7.84459472e-01, -1.39909377e-02, -5.95526159e-01],</span><span class="hljs-comment">#        [-9.41911936e-01, -1.30074513e+00, -6.23348076e-03]]],</span><span class="hljs-comment">#      dtype=float32)&gt;</span><span class="hljs-comment"># 取G 通道数据</span>x[:, :, :, <span class="hljs-number">1</span>]<span class="hljs-comment">#Out[15]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(4, 32, 32), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[ 1.0090125 , -0.24564391,  0.5095773 , ...,  1.5169894 ,</span><span class="hljs-comment">#         -0.18337473, -1.5871915 ],</span><span class="hljs-comment">#        [ 0.17341255, -1.3007451 , -1.2544614 , ..., -0.16909435,</span><span class="hljs-comment">#         -1.8166164 , -0.44045535],</span><span class="hljs-comment">#        [-0.5260793 ,  0.34341118, -0.83735013, ..., -0.14702302,</span><span class="hljs-comment">#         -1.0870305 , -0.30651042],</span><span class="hljs-comment">#        ...,</span>x[..., <span class="hljs-number">1</span>]<span class="hljs-comment">#Out[16]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(4, 32, 32), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[ 1.0090125 , -0.24564391,  0.5095773 , ...,  1.5169894 ,</span><span class="hljs-comment">#         -0.18337473, -1.5871915 ],</span><span class="hljs-comment">#        [ 0.17341255, -1.3007451 , -1.2544614 , ..., -0.16909435,</span><span class="hljs-comment">#         -1.8166164 , -0.44045535],</span><span class="hljs-comment">#        [-0.5260793 ,  0.34341118, -0.83735013, ..., -0.14702302,</span><span class="hljs-comment">#         -1.0870305 , -0.30651042],</span><span class="hljs-comment">#        ...,</span></code></pre><h1 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h1><h2 id="改变试图"><a href="#改变试图" class="headerlink" title="改变试图"></a>改变试图</h2><pre><code class="hljs python"><span class="hljs-comment"># 生成向量</span>x = tf.<span class="hljs-built_in">range</span>(<span class="hljs-number">96</span>)<span class="hljs-comment"># 改变x 的视图，获得4D 张量，存储并未改变</span>tf.reshape(x, [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>])<span class="hljs-comment">#Out[5]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 4, 4, 3), dtype=int32, numpy=</span><span class="hljs-comment">#array([[[[ 0,  1,  2],</span><span class="hljs-comment">#         [ 3,  4,  5],</span><span class="hljs-comment">#         [ 6,  7,  8],</span><span class="hljs-comment">#         [ 9, 10, 11]],</span><span class="hljs-comment">#         ...,</span><span class="hljs-comment">#        [[84, 85, 86],</span><span class="hljs-comment">#         [87, 88, 89],</span><span class="hljs-comment">#         [90, 91, 92],</span><span class="hljs-comment">#         [93, 94, 95]]]])&gt;</span></code></pre><p>在 TensorFlow 中，可以通过张量的ndim 和shape 成员属性获得张量的维度数和形状：</p><pre><code class="hljs python"><span class="hljs-comment"># 获取张量的维度数和形状列表</span>x.ndim, x.shape<span class="hljs-comment">#Out[6]: (1, TensorShape([96]))</span></code></pre><p>通过 tf.reshape(x, new_shape)，可以将张量的视图任意地合法改变，例如：</p><pre><code class="hljs python">tf.reshape(x, [<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>])<span class="hljs-comment">#Out[7]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 48), dtype=int32, numpy=</span><span class="hljs-comment">#array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,</span><span class="hljs-comment">#        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,</span><span class="hljs-comment">#        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],</span><span class="hljs-comment">#       [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,</span><span class="hljs-comment">#        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,</span><span class="hljs-comment">#        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]])&gt;</span></code></pre><p>其中的参数−1表示当前轴上长度需要根据张量总元素不变的法则自动推导，从而方便用户书写<br>$$<br>\frac{2<em>4</em>4*3}{2}=48<br>$$</p><p>再次改变数据的视图为[2,16,3] ，实现如下：</p><pre><code class="hljs python">tf.reshape(x, [<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])<span class="hljs-comment">#Out[8]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 16, 3), dtype=int32, numpy=</span><span class="hljs-comment">#array([[[ 0,  1,  2],...,</span><span class="hljs-comment">#        [45, 46, 47]],...,</span></code></pre><h2 id="增、删维度"><a href="#增、删维度" class="headerlink" title="增、删维度"></a>增、删维度</h2><h3 id="增加维度"><a href="#增加维度" class="headerlink" title="增加维度"></a>增加维度</h3><p>考虑一个具体例子，一张28 × 28大小的灰度图片的数据保存为shape 为[28,28]的张量，在末尾给张量增加一新维度，定义为通道数维度，此时张量的shape 变为[28,28,1]，实现如下：</p><pre><code class="hljs python"><span class="hljs-comment"># 产生矩阵</span>x = tf.random.uniform([<span class="hljs-number">28</span>, <span class="hljs-number">28</span>], maxval=<span class="hljs-number">10</span>, dtype=tf.int32)print(x)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[4 6 9 7 5 8 5 8 5 6 1 6 3 1 6 1 2 9 2 0 0 2 1 7 1 3 1 7]...</span><span class="hljs-comment"># [4 1 6 5 8 1 8 0 5 9 4 5 6 5 4 0 8 1 0 8 1 1 5 8 7 1 7 9]], shape=(28, 28), dtype=int32)</span><span class="hljs-comment"># 通过tf.expand_dims(x, axis)可在指定的axis 轴前可以插入一个新的维度：</span><span class="hljs-comment"># axis=2 表示宽维度后面的一个维度</span>x = tf.expand_dims(x, axis=<span class="hljs-number">2</span>)print(x)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[[4]...</span><span class="hljs-comment">#  [9]]], shape=(28, 28, 1), dtype=int32)</span><span class="hljs-comment"># 高维度之前插入新维度</span>x = tf.expand_dims(x, axis=<span class="hljs-number">0</span>)print(x)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[[[4]...</span><span class="hljs-comment">#   [9]]]], shape=(1, 28, 28, 1), dtype=int32)</span></code></pre><h3 id="删除维度"><a href="#删除维度" class="headerlink" title="删除维度"></a>删除维度</h3><p>通过tf.squeeze(x, axis)函数，axis 参数为待删除的维度的索引号</p><pre><code class="hljs python"><span class="hljs-comment"># 删除图片数量维度</span>x = tf.squeeze(x, axis=<span class="hljs-number">0</span>)print(x)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[[4]...</span><span class="hljs-comment">#  [9]]], shape=(28, 28, 1), dtype=int32)</span><span class="hljs-comment"># 删除图片通道数维度</span>x = tf.squeeze(x, axis=<span class="hljs-number">2</span>)print(x)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[4 6 9 7 5 8 5 8 5 6 1 6 3 1 6 1 2 9 2 0 0 2 1 7 1 3 1 7]...</span><span class="hljs-comment"># [4 1 6 5 8 1 8 0 5 9 4 5 6 5 4 0 8 1 0 8 1 1 5 8 7 1 7 9]], shape=(28, 28), dtype=int32)</span></code></pre><p>如果不指定维度参数 axis，即tf.squeeze(x)，那么它会默认删除所有长度为1的维度。</p><pre><code class="hljs python">x = tf.random.uniform([<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>], maxval=<span class="hljs-number">10</span>, dtype=tf.int32)<span class="hljs-comment"># 删除所有长度为1的维度</span>tf.squeeze(x)<span class="hljs-comment">#Out[15]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(28, 28), dtype=int32, numpy=</span><span class="hljs-comment">#array([[0, 8, 3, 2, 3, 3, 0, 5, 0, 1, 4, 7, 6, 7, 2, 3, 2, 6, 5, 1, 5, 6,</span><span class="hljs-comment">#        5, 1, 3, 1, 9, 0],</span></code></pre><h3 id="交换维度"><a href="#交换维度" class="headerlink" title="交换维度"></a>交换维度</h3><pre><code class="hljs python">x = tf.random.normal([<span class="hljs-number">2</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">3</span>])<span class="hljs-comment"># 交换维度</span>tf.transpose(x, perm=[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<span class="hljs-comment">#Out[16]: </span><span class="hljs-comment">#&lt;tf.Tensor: shape=(2, 3, 32, 32), dtype=float32, numpy=</span><span class="hljs-comment">#array([[[[-7.99596786e-01, -5.61527647e-02, -9.59246576e-01, ...,</span></code></pre><h3 id="复制数据"><a href="#复制数据" class="headerlink" title="复制数据"></a>复制数据</h3><pre><code class="hljs python"><span class="hljs-comment"># 创建向量b</span>b = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])<span class="hljs-comment"># 插入新维度，变成矩阵</span>b = tf.expand_dims(b, axis=<span class="hljs-number">0</span>)print(b)<span class="hljs-comment">#tf.Tensor([[1 2]], shape=(1, 2), dtype=int32)</span><span class="hljs-comment"># 样本维度上复制一份</span>b = tf.tile(b, multiples=[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>])print(b)<span class="hljs-comment">#tf.Tensor(</span><span class="hljs-comment">#[[1 2 1 2 1 2]</span><span class="hljs-comment"># [1 2 1 2 1 2]], shape=(2, 6), dtype=int32)</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>TensorFlow</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Tensorflow</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Django_rest_framework_jwt</title>
    <link href="/2020/03/10/2020-3-10-Django_rest_framework_jwt/"/>
    <url>/2020/03/10/2020-3-10-Django_rest_framework_jwt/</url>
    
    <content type="html"><![CDATA[<h1 id="自定义验证错误返回"><a href="#自定义验证错误返回" class="headerlink" title="自定义验证错误返回"></a>自定义验证错误返回</h1><p>在使用Django做前端后端项目时，登陆认证方法往往使用的是jwt_token，但是想自定义登陆成功和失败的返回体。<br>打开 <code>rest_framework_jwt/settings.py</code>添加</p><pre><code class="hljs prolog"><span class="hljs-symbol">DEFAULTS</span> = &#123;    ...    <span class="hljs-string">&#x27;JWT_RESPONSE_PAYLOAD_HANDLER&#x27;</span>:    <span class="hljs-string">&#x27;rest_framework_jwt.utils.jwt_response_payload_handler&#x27;</span>,        <span class="hljs-string">&#x27;JWT_RESPONSE_PAYLOAD_ERROR_HANDLER&#x27;</span>:    <span class="hljs-string">&#x27;rest_framework_jwt.utils.jwt_response_payload_error_handler&#x27;</span>,    ...&#125;# <span class="hljs-symbol">List</span> of settings that may be in string import notation.<span class="hljs-symbol">IMPORT_STRINGS</span> = (    ...    <span class="hljs-string">&#x27;JWT_RESPONSE_PAYLOAD_HANDLER&#x27;</span>,    <span class="hljs-string">&#x27;JWT_RESPONSE_PAYLOAD_ERROR_HANDLER&#x27;</span>,    <span class="hljs-string">&#x27;JWT_GET_USER_SECRET_KEY&#x27;</span>,)</code></pre><p>在 <code>rest_framework_jwt/utils.py</code>末尾添加</p><pre><code class="hljs python">...<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">jwt_response_payload_error_handler</span>(<span class="hljs-params">serializer, request=<span class="hljs-literal">None</span></span>):</span>    <span class="hljs-keyword">return</span> &#123;        <span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;username or password is error.&quot;</span>,        <span class="hljs-string">&quot;status&quot;</span>: <span class="hljs-number">400</span>,        <span class="hljs-string">&quot;detail&quot;</span>: serializer.errors    &#125;</code></pre><p>在<code>rest_framework_jwt/views.py</code>修改</p><pre><code class="hljs python">jwt_response_payload_handler = api_settings.JWT_RESPONSE_PAYLOAD_HANDLERjwt_response_payload_error_handler = api_settings.JWT_RESPONSE_PAYLOAD_ERROR_HANDLER<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JSONWebTokenAPIView</span>(<span class="hljs-params">APIView</span>):</span>    <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">    Base API View that various JWT interactions inherit from.</span><span class="hljs-string">    &quot;&quot;&quot;</span>    ...    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">post</span>(<span class="hljs-params">self, request, *args, **kwargs</span>):</span>        ...        <span class="hljs-comment"># return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)</span>        error_data = jwt_response_payload_error_handler(serializer, request)        <span class="hljs-keyword">return</span> Response(error_data, status=status.HTTP_200_OK)</code></pre>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python3</tag>
      
      <tag>Django2.2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>mysql 数据库常用命令</title>
    <link href="/2020/01/30/2020-1-30-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C/"/>
    <url>/2020/01/30/2020-1-30-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><p><code>mysql -u root -p</code></p><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><p><code> CREATE DATABASE &lt;数据库名&gt;;</code></p><p><code>create database &lt;数据库名&gt; default character set utf8mb4 collate utf8mb4_unicode_ci;</code></p><h3 id="选择数据库"><a href="#选择数据库" class="headerlink" title="选择数据库"></a>选择数据库</h3><p><code>USE &lt;数据库名&gt;;</code></p><h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><p><code>drop database &lt;数据库名&gt;;</code></p><h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><p><code>CREATE USER &#39;&lt;用户名&gt;&#39;@&#39;host&#39; IDENTIFIED BY &#39;&lt;密码&gt;&#39;;</code><br>host：指定该用户在哪个主机上可以登陆，如果是本地用户可用 localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符%</p><h3 id="删除用户"><a href="#删除用户" class="headerlink" title="删除用户"></a>删除用户</h3><p><code>Delete FROM user Where User=&#39;&lt;用户名&gt;&#39; and Host=&#39;localhost&#39;;</code></p><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><p><code>GRANT privileges ON &lt;数据库名&gt;.&lt;表名&gt; TO &#39;username&#39;@&#39;host&#39;</code></p><p>privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL</p><p>如果要授予该用户对所有数据库和表的相应操作权限则可用<code>*</code>表示，如<code>*.*</code></p><p>授权test用户拥有testDB数据库的所有权限（某个数据库的所有权限）：</p><p><code>grant all privileges on testDB.* to &#39;test&#39;@&#39;localhost&#39; identified by &#39;1234&#39;;</code></p><p><code>mysql&gt;flush privileges;</code></p><h1 id="mysql5-7-解决不用密码也能登录"><a href="#mysql5-7-解决不用密码也能登录" class="headerlink" title="mysql5.7 解决不用密码也能登录"></a>mysql5.7 解决不用密码也能登录</h1><pre><code class="hljs sql"><span class="hljs-keyword">use</span> mysql;<span class="hljs-keyword">update</span> <span class="hljs-keyword">user</span> <span class="hljs-keyword">set</span> authentication_string=<span class="hljs-keyword">PASSWORD</span>(<span class="hljs-string">&quot;密码&quot;</span>) <span class="hljs-keyword">where</span> <span class="hljs-keyword">user</span>=<span class="hljs-string">&#x27;root&#x27;</span>;<span class="hljs-keyword">update</span> <span class="hljs-keyword">user</span> <span class="hljs-keyword">set</span> <span class="hljs-keyword">plugin</span>=<span class="hljs-string">&quot;mysql_native_password&quot;</span>;<span class="hljs-keyword">flush</span> <span class="hljs-keyword">privileges</span>;quit;</code></pre>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Django 项目部署</title>
    <link href="/2020/01/30/2020-1-30-Django%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/"/>
    <url>/2020/01/30/2020-1-30-Django%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="安装-nginx"><a href="#安装-nginx" class="headerlink" title="安装 nginx"></a>安装 nginx</h2><p><code>sudo apt-get install nginx</code></p><h2 id="安装-mysql-数据库"><a href="#安装-mysql-数据库" class="headerlink" title="安装 mysql 数据库"></a>安装 mysql 数据库</h2><h2 id="配置虚拟环境"><a href="#配置虚拟环境" class="headerlink" title="配置虚拟环境"></a>配置虚拟环境</h2><p><code>virtualenv venv</code></p><h2 id="激活虚拟环境"><a href="#激活虚拟环境" class="headerlink" title="激活虚拟环境"></a>激活虚拟环境</h2><p><code>source venv/bin/activate</code></p><h2 id="安装-uwsgi"><a href="#安装-uwsgi" class="headerlink" title="安装 uwsgi"></a>安装 uwsgi</h2><p><code>pip install uwsgi</code></p><p><code>sudo apt-get install mysql-server</code></p><h2 id="生成-requirements-txt"><a href="#生成-requirements-txt" class="headerlink" title="生成 requirements.txt"></a>生成 requirements.txt</h2><p><code>pip freeze &gt; requirements.txt</code></p><h2 id="安装-requirements-txt"><a href="#安装-requirements-txt" class="headerlink" title="安装 requirements.txt"></a>安装 requirements.txt</h2><p><code>pip install -r requirements.txt</code></p><h2 id="配置-nginx-conf"><a href="#配置-nginx-conf" class="headerlink" title="配置 nginx.conf"></a>配置 nginx.conf</h2><pre><code class="hljs nginx"><span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">charset</span>      utf-<span class="hljs-number">8</span>;    <span class="hljs-attribute">listen</span>       <span class="hljs-number">443</span>;    <span class="hljs-attribute">server_name</span>  api.domian.com;    <span class="hljs-attribute">root</span> /var/www/api;        <span class="hljs-attribute">ssl</span> <span class="hljs-literal">on</span>;    <span class="hljs-attribute">ssl_certificate</span> /var/www/api/1_api.domian.com_bundle.crt;    <span class="hljs-attribute">ssl_certificate_key</span> /var/www/api/2_api.domian.com.key;    <span class="hljs-attribute">ssl_session_timeout</span> <span class="hljs-number">5m</span>;    <span class="hljs-attribute">ssl_protocols</span> TLSv1 TLSv1.<span class="hljs-number">1</span> TLSv1.<span class="hljs-number">2</span>;    <span class="hljs-attribute">ssl_ciphers</span> ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;    <span class="hljs-attribute">ssl_prefer_server_ciphers</span> <span class="hljs-literal">on</span>;    <span class="hljs-attribute">location</span> / &#123;        <span class="hljs-attribute">include</span>   uwsgi_params;        <span class="hljs-attribute">uwsgi_pass</span>   <span class="hljs-number">127.0.0.1:8080</span>;    &#125;    <span class="hljs-comment"># 指向django的media目录</span>    <span class="hljs-attribute">location</span> /media  &#123;    <span class="hljs-attribute">alias</span> /var/www/api/media; &#125;<span class="hljs-comment"># 指向django的static目录</span><span class="hljs-attribute">location</span> /static &#123;    <span class="hljs-attribute">alias</span> /var/www/api/static; &#125;&#125;<span class="hljs-section">server</span> &#123;    <span class="hljs-attribute">listen</span> <span class="hljs-number">80</span>;    <span class="hljs-attribute">server_name</span> course.zguolee.cn;     <span class="hljs-attribute">rewrite</span><span class="hljs-regexp"> ^(.*)$</span> https://$host<span class="hljs-variable">$1</span> <span class="hljs-literal">permanent</span>;    <span class="hljs-attribute">location</span> / &#123;    <span class="hljs-attribute">index</span> index.html index.htm;    &#125;&#125;</code></pre><h2 id="配置-uwsgi-ini"><a href="#配置-uwsgi-ini" class="headerlink" title="配置 uwsgi.ini"></a>配置 uwsgi.ini</h2><pre><code class="hljs ini"><span class="hljs-section">[uwsgi]</span><span class="hljs-comment"># variables</span><span class="hljs-attr">projectname</span> = projectname<span class="hljs-attr">projectdomain</span> = api.domian.com<span class="hljs-attr">base</span> = /var/www/api<span class="hljs-comment"># config</span><span class="hljs-attr">master</span> = <span class="hljs-literal">true</span><span class="hljs-attr">protocol</span> = uwsgi<span class="hljs-attr">env</span> = DJANGO_SETTINGS_MODULE=%(projectname).settings<span class="hljs-attr">pythonpath</span> = %(base)/%(projectname)<span class="hljs-attr">module</span> = %(projectname).wsgi<span class="hljs-attr">socket</span> = <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">8080</span>   <span class="hljs-comment"># 存进程id的文件</span><span class="hljs-attr">pidfile</span>=uwsgi.pid<span class="hljs-comment"># 日志文件</span><span class="hljs-attr">daemonize</span>=uwsgi.log</code></pre><p><code>python manage.py collectstatic</code></p><p><code>service nginx start</code> 启动 <strong>nginx</strong> 转发 </p><p><code>uwsgi --ini uwsgi.ini</code></p>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Dajngo2.2</tag>
      
      <tag>Python3.7</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模板文件</title>
    <link href="/2019/10/10/%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6/"/>
    <url>/2019/10/10/%E6%A8%A1%E6%9D%BF%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="标题一"><a href="#标题一" class="headerlink" title="标题一"></a>标题一</h1><blockquote><p>引用内容</p></blockquote><p>测试内容</p><h2 id="标题二"><a href="#标题二" class="headerlink" title="标题二"></a>标题二</h2><p>测试内容</p><div class="note note-success">            <p>文字 或者 <code>markdown</code> 均可</p>          </div><h1 id="源代码"><a href="#源代码" class="headerlink" title="源代码"></a>源代码</h1><pre><code class="hljs markdown">---title: 模板文件tags: [Hexo, Fluid]excerpt: 这里是是摘要index<span class="hljs-emphasis">_img: /img/default.png</span><span class="hljs-emphasis">banner_</span>img: /img/background.jpgdate: 2019-10-10 10:00:00---<span class="hljs-section"># 标题一</span><span class="hljs-quote">&gt; 引用内容</span>测试内容<span class="hljs-section">## 标题二</span>测试内容&#123;% note success %&#125;文字 或者 <span class="hljs-code">`markdown`</span> 均可&#123;% endnote %&#125;<span class="hljs-section">### 标题三</span>测试内容<span class="hljs-section">## 参考</span>[<span class="hljs-symbol">^1</span>]: <span class="hljs-link">https://hexo.fluid-dev.com/docs/</span>[<span class="hljs-symbol">^2</span>]: <span class="hljs-link">参考资料2</span></code></pre><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span><a href="https://hexo.fluid-dev.com/docs/">https://hexo.fluid-dev.com/docs/</a><a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>参考资料2<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Fluid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模板文件</title>
    <link href="/2019/10/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    <url>/2019/10/10/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="从-URL-输入到页面展现发生了什么"><a href="#从-URL-输入到页面展现发生了什么" class="headerlink" title="从 URL 输入到页面展现发生了什么?"></a>从 URL 输入到页面展现发生了什么?</h2><ol><li>在浏览器中输入url</li><li>应用层DNS解析域名：先本地查找，再查询DNS服务器</li><li>应用层客户端发送HTTP请求</li><li>传输层TCP传输报文：三次握手</li><li>网络层IP协议查询MAC地址</li><li>数据到达数据链路层</li><li>服务器接收数据</li><li>服务器响应请求</li><li>服务器返回相应文件</li><li>页面渲染。解析HTML以构建DOM树 –&gt; 构建渲染树 –&gt; 布局渲染树 –&gt; 绘制渲染树。</li></ol><h2 id="OSI的体系结构"><a href="#OSI的体系结构" class="headerlink" title="OSI的体系结构"></a>OSI的体系结构</h2><ul><li>应用层：文件传输，常用协议，snmp，FTP</li><li>表示层：数据格式化，代码转换，数据加密</li><li>会话层：建立、解除会话</li><li>传输层：负责端到端的可靠性传输，TCP与UDP</li><li>网络层：为数据包选择路由</li><li>数据链路层：传输有地址的帧</li><li>物理层：二进制的数据形式在物理媒体上传输数据</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Fluid</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
